{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b360085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8c87ee",
   "metadata": {},
   "source": [
    "## Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a75dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the experiment results\n",
    "df = pd.read_csv('../model_comparison_results.csv')\n",
    "print(f\"Loaded {len(df)} experiment results\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d55273",
   "metadata": {},
   "source": [
    "## Overall Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe17ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Overall Mean R²\n",
    "df_sorted = df.sort_values('Overall Mean R²', ascending=False)\n",
    "\n",
    "# Display summary\n",
    "summary_cols = ['model', 'Overall Mean R²', 'epochs', 'best_epoch', 'best_test_loss', 'latent_dim']\n",
    "available_cols = [c for c in summary_cols if c in df.columns]\n",
    "df_sorted[available_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06061e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of Overall Mean R²\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "colors = sns.color_palette('husl', len(df_sorted))\n",
    "bars = ax.barh(df_sorted['model'], df_sorted['Overall Mean R²'], color=colors)\n",
    "\n",
    "ax.set_xlabel('Overall Mean R²', fontsize=12)\n",
    "ax.set_ylabel('Model', fontsize=12)\n",
    "ax.set_title('Model Comparison - Overall Mean R²', fontsize=14)\n",
    "ax.set_xlim(left=min(0, df_sorted['Overall Mean R²'].min() - 0.1))\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, df_sorted['Overall Mean R²']):\n",
    "    ax.text(val + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "            f'{val:.4f}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/model_comparison_overall_r2.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f84b8ea",
   "metadata": {},
   "source": [
    "## Per-Target Property Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dac573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract R² columns for each target property\n",
    "r2_cols = [col for col in df.columns if col.endswith('(R²)')]\n",
    "print(f\"Target properties: {len(r2_cols)}\")\n",
    "print(r2_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afdabd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap of R² scores per model and target\n",
    "if r2_cols:\n",
    "    r2_data = df_sorted.set_index('model')[r2_cols]\n",
    "    r2_data.columns = [col.replace(' (R²)', '') for col in r2_data.columns]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    sns.heatmap(r2_data, annot=True, fmt='.3f', cmap='RdYlGn', center=0,\n",
    "                ax=ax, cbar_kws={'label': 'R² Score'})\n",
    "    ax.set_title('R² Score by Model and Target Property', fontsize=14)\n",
    "    ax.set_xlabel('Target Property', fontsize=12)\n",
    "    ax.set_ylabel('Model', fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../figures/r2_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534e68eb",
   "metadata": {},
   "source": [
    "## Confidence Intervals Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee999a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot R² with confidence intervals for the best model\n",
    "best_model = df_sorted.iloc[0]['model']\n",
    "best_row = df_sorted.iloc[0]\n",
    "\n",
    "print(f\"Best model: {best_model}\")\n",
    "\n",
    "# Extract target properties and their CIs\n",
    "targets = []\n",
    "r2_scores = []\n",
    "ci_lows = []\n",
    "ci_highs = []\n",
    "\n",
    "for col in r2_cols:\n",
    "    target_name = col.replace(' (R²)', '')\n",
    "    targets.append(target_name)\n",
    "    r2_scores.append(best_row[col])\n",
    "    \n",
    "    ci_low_col = f\"{target_name} (CI Low)\"\n",
    "    ci_high_col = f\"{target_name} (CI High)\"\n",
    "    \n",
    "    ci_lows.append(best_row.get(ci_low_col, 0))\n",
    "    ci_highs.append(best_row.get(ci_high_col, 0))\n",
    "\n",
    "if targets:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    x = np.arange(len(targets))\n",
    "    r2_scores = np.array(r2_scores)\n",
    "    ci_lows = np.array(ci_lows)\n",
    "    ci_highs = np.array(ci_highs)\n",
    "    \n",
    "    # Error bars\n",
    "    yerr_low = r2_scores - ci_lows\n",
    "    yerr_high = ci_highs - r2_scores\n",
    "    \n",
    "    bars = ax.bar(x, r2_scores, yerr=[yerr_low, yerr_high], capsize=5, \n",
    "                  color=sns.color_palette('husl', len(targets)), alpha=0.8)\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(targets, rotation=45, ha='right')\n",
    "    ax.set_xlabel('Target Property', fontsize=12)\n",
    "    ax.set_ylabel('R² Score', fontsize=12)\n",
    "    ax.set_title(f'R² Scores with 95% CI - {best_model}', fontsize=14)\n",
    "    ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../figures/best_model_r2_with_ci.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd81a4eb",
   "metadata": {},
   "source": [
    "## Training Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d01c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best epoch analysis\n",
    "if 'best_epoch' in df.columns:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Best epoch vs total epochs\n",
    "    ax1 = axes[0]\n",
    "    x = np.arange(len(df_sorted))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax1.bar(x - width/2, df_sorted['epochs'], width, label='Total Epochs', alpha=0.7)\n",
    "    ax1.bar(x + width/2, df_sorted['best_epoch'], width, label='Best Epoch', alpha=0.7)\n",
    "    \n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(df_sorted['model'], rotation=45, ha='right')\n",
    "    ax1.set_ylabel('Epochs')\n",
    "    ax1.set_title('Total Epochs vs Best Epoch')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Best test loss\n",
    "    ax2 = axes[1]\n",
    "    if 'best_test_loss' in df.columns:\n",
    "        bars = ax2.bar(df_sorted['model'], df_sorted['best_test_loss'], \n",
    "                       color=sns.color_palette('husl', len(df_sorted)))\n",
    "        ax2.set_xticklabels(df_sorted['model'], rotation=45, ha='right')\n",
    "        ax2.set_ylabel('Best Test Loss')\n",
    "        ax2.set_title('Best Test Loss by Model')\n",
    "        \n",
    "        for bar, val in zip(bars, df_sorted['best_test_loss']):\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height(), \n",
    "                    f'{val:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../figures/training_dynamics.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850c8486",
   "metadata": {},
   "source": [
    "## Model Comparison Across All Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8c317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouped bar chart comparing all models across targets\n",
    "if r2_cols:\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    \n",
    "    n_models = len(df)\n",
    "    n_targets = len(r2_cols)\n",
    "    x = np.arange(n_targets)\n",
    "    width = 0.8 / n_models\n",
    "    \n",
    "    colors = sns.color_palette('husl', n_models)\n",
    "    \n",
    "    for i, (idx, row) in enumerate(df_sorted.iterrows()):\n",
    "        values = [row[col] for col in r2_cols]\n",
    "        offset = (i - n_models/2 + 0.5) * width\n",
    "        ax.bar(x + offset, values, width, label=row['model'], color=colors[i], alpha=0.8)\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([col.replace(' (R²)', '') for col in r2_cols], rotation=45, ha='right')\n",
    "    ax.set_xlabel('Target Property', fontsize=12)\n",
    "    ax.set_ylabel('R² Score', fontsize=12)\n",
    "    ax.set_title('Model Comparison Across All Target Properties', fontsize=14)\n",
    "    ax.legend(title='Model', bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "    ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../figures/model_comparison_all_targets.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2067b880",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary\n",
    "print(\"=\"*60)\n",
    "print(\"EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nBest Model: {df_sorted.iloc[0]['model']}\")\n",
    "print(f\"Overall Mean R²: {df_sorted.iloc[0]['Overall Mean R²']:.4f}\")\n",
    "\n",
    "if 'best_epoch' in df.columns:\n",
    "    print(f\"Best Epoch: {df_sorted.iloc[0]['best_epoch']}\")\n",
    "if 'best_test_loss' in df.columns:\n",
    "    print(f\"Best Test Loss: {df_sorted.iloc[0]['best_test_loss']:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"All Models Ranking:\")\n",
    "print(\"-\"*60)\n",
    "for i, row in df_sorted.iterrows():\n",
    "    print(f\"  {row['model']}: R²={row['Overall Mean R²']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7c7c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of R² scores\n",
    "if r2_cols:\n",
    "    print(\"\\nR² Score Statistics per Target Property:\")\n",
    "    print(\"-\"*60)\n",
    "    stats_df = df[r2_cols].describe().T\n",
    "    stats_df.columns = ['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
    "    stats_df.index = [col.replace(' (R²)', '') for col in stats_df.index]\n",
    "    print(stats_df[['mean', 'std', 'min', 'max']].round(4))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
